# -*- coding: utf-8 -*-
"""fine_tuning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JZW39euLG2JHhctJqHmkoZ8V04C-CkxM
"""

# !pip install torch datasets transformers trl git+https://github.com/unslothai/unsloth.git

# !pip install bitsandbytes triton

# !pip install unsloth-zoo

# !pip install xformers>=0.0.27

from google.colab import drive
import os
import torch
from datasets import load_dataset
from transformers import TrainingArguments
from trl import SFTTrainer
from unsloth import FastLanguageModel, is_bfloat16_supported

##############################################
# CONFIGURATION
##############################################
MODEL_NAME = "unsloth/Qwen2.5-7B"   # Base model to fine-tune
DATASET_PATH = "train.jsonl"        # Your prepared dataset file
OUTPUT_DIR = "outputs"              # Directory to save fine-tuned model and logs

MAX_SEQ_LENGTH = 2048
DTYPE = None          # Auto detects precision (e.g., float16 on T4)
LOAD_IN_4BIT = True   # 4-bit quantization for memory efficiency
RANK = 16             # LoRA rank
LORA_ALPHA = 16
LORA_DROPOUT = 0.0

LEARNING_RATE = 2e-4
MAX_STEPS = 60  # For demo purposes, adjust for actual training
BATCH_SIZE = 2   # Adjust based on GPU memory
GRAD_ACC_STEPS = 4

##############################################
# DATA ASSUMPTIONS
##############################################
# Each sample in train.jsonl is expected to have:
# {
#   "instruction": "User: I feel hopeless.",
#   "input": "",
#   "output": "User_Emotion: depression\nStrategy: ask open-ended question\nSystem_Emotion: empathetic\nResponse: Could you share more about why you feel this way?"
# }
#
# We'll combine these fields into a single "text" field for training:
# text = instruction + "\n" + input + "\n" + output + <eos_token>
# The model will learn to predict the output (including emotion labels and strategy) given the instruction and input.

##############################################
# FUNCTIONS
##############################################


def load_model_and_tokenizer():
    """
    Load the base model and tokenizer using Unsloth's FastLanguageModel.
    Enables memory-efficient loading (e.g., 4-bit quantization).
    """
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name=MODEL_NAME,
        max_seq_length=MAX_SEQ_LENGTH,
        dtype=DTYPE,
        load_in_4bit=LOAD_IN_4BIT,
    )
    return model, tokenizer


def apply_lora_adapters(model):
    """
    Apply LoRA adapters to the model for parameter-efficient fine-tuning.
    This modifies only a small subset of model parameters, reducing training cost.
    """
    model = FastLanguageModel.get_peft_model(
        model,
        r=RANK,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                        "gate_proj", "up_proj", "down_proj"],
        lora_alpha=LORA_ALPHA,
        lora_dropout=LORA_DROPOUT,
        bias="none",
        use_gradient_checkpointing="unsloth",  # More memory efficient
        random_state=3407,
        use_rslora=False,
        loftq_config=None,
    )
    return model


def format_example(example, eos_token):
    """
    Combine instruction, input, and output fields into a single text string.
    The model sees the user's instruction and optional input, and must produce
    the annotated response, including user emotion, strategy, and system response.
    """
    instruction = example["instruction"].strip()
    input_text = example["input"].strip()
    output_text = example["output"].strip()
    text = f"{instruction}\n{input_text}\n{output_text}{eos_token}"
    return {"text": text}


def load_and_prepare_dataset(tokenizer):
    """
    Load the dataset from JSONL and format it into a 'text' field suitable for SFT training.
    """
    dataset = load_dataset("json", data_files=DATASET_PATH, split="train")

    eos_token = tokenizer.eos_token if tokenizer.eos_token else "<|endoftext|>"
    dataset = dataset.map(lambda ex: format_example(
        ex, eos_token), batched=False)
    return dataset


def train_model(model, tokenizer, dataset):
    """
    Configure the training arguments and run the supervised fine-tuning.
    """
    trainer = SFTTrainer(
        model=model,
        tokenizer=tokenizer,
        train_dataset=dataset,
        dataset_text_field="text",
        max_seq_length=MAX_SEQ_LENGTH,
        dataset_num_proc=2,
        packing=False,
        args=TrainingArguments(
            per_device_train_batch_size=BATCH_SIZE,
            gradient_accumulation_steps=GRAD_ACC_STEPS,
            warmup_steps=5,
            max_steps=MAX_STEPS,
            learning_rate=LEARNING_RATE,
            fp16=not is_bfloat16_supported(),
            bf16=is_bfloat16_supported(),
            logging_steps=1,
            optim="adamw_8bit",
            weight_decay=0.01,
            lr_scheduler_type="linear",
            seed=3407,
            output_dir=OUTPUT_DIR,
            report_to="none",
        ),
    )

    print("Starting training...")
    trainer_stats = trainer.train()
    print(f"Training completed in {
          trainer_stats.metrics['train_runtime']} seconds.")


def run_inference(model, tokenizer, user_query):
    """
    Test inference by providing a user query.
    The model should produce an annotated response with user emotion, strategy, and system emotion.
    """
    FastLanguageModel.for_inference(model)  # Optimize model for inference
    inputs = tokenizer([user_query], return_tensors="pt").to("cuda")
    outputs = model.generate(**inputs, max_new_tokens=128, use_cache=True)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response

##############################################
# MAIN EXECUTION
##############################################


def main():
    # Ensure output directory exists
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # Load base model and tokenizer
    model, tokenizer = load_model_and_tokenizer()
    # Apply LoRA adapters
    model = apply_lora_adapters(model)
    # Load and prepare training dataset
    dataset = load_and_prepare_dataset(tokenizer)
    # Train the model
    train_model(model, tokenizer, dataset)

    # Save LoRA adapters and tokenizer
    model.save_pretrained(os.path.join(OUTPUT_DIR, "lora_model"))
    tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, "lora_model"))
    print("Model and tokenizer saved to lora_model directory.")

    # Test inference
    test_prompt = "User: I've been feeling very anxious lately.\n\n"
    response = run_inference(model, tokenizer, test_prompt)
    print("Sample Inference Response:\n", response)


if __name__ == "__main__":
    main()

drive.mount('/content/drive')
